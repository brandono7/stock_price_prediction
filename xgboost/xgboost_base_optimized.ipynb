{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import RandomizedSearchCV, HalvingGridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, f1_score, \n",
    "                            confusion_matrix, roc_auc_score,\n",
    "                            RocCurveDisplay)\n",
    "\n",
    "train_df = pd.read_csv(\"./datasets/train.csv\")\n",
    "val_df = pd.read_csv(\"./datasets/val.csv\")\n",
    "test_df = pd.read_csv(\"./datasets/test.csv\")\n",
    "\n",
    "# Define features and binary classification target\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "train_df['target'] = (train_df['log_return'] > 0).astype(int)\n",
    "val_df['target'] = (val_df['log_return'] > 0).astype(int)\n",
    "test_df['target'] = (test_df['log_return'] > 0).astype(int)\n",
    "\n",
    "# Extract features and target\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_val = val_df[features]\n",
    "y_val = val_df['target']\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df['target']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high is out of bounds for int32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     11\u001b[39m param_dist = {\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m#  20 choices from 50 → 2 000\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m:       \u001b[38;5;28mlist\u001b[39m(np.linspace(\u001b[32m50\u001b[39m, \u001b[32m2000\u001b[39m, \u001b[32m10\u001b[39m, dtype=\u001b[38;5;28mint\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_bin\u001b[39m\u001b[33m'\u001b[39m:            \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m64\u001b[39m, \u001b[32m513\u001b[39m, \u001b[32m32\u001b[39m))\n\u001b[32m     45\u001b[39m }\n\u001b[32m     47\u001b[39m rand_search = RandomizedSearchCV(\n\u001b[32m     48\u001b[39m     estimator=base_clf,\n\u001b[32m     49\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     n_jobs=\u001b[32m1\u001b[39m\n\u001b[32m     56\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mrand_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRandomSearch best params:\u001b[39m\u001b[33m\"\u001b[39m, rand_search.best_params_)\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRandomSearch best CV acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[33m\"\u001b[39m.format(rand_search.best_score_))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\cs3244\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\cs3244\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\cs3244\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\cs3244\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:959\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    957\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_candidates\u001b[39m(candidate_params, cv=\u001b[38;5;28;01mNone\u001b[39;00m, more_results=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    958\u001b[39m     cv = cv \u001b[38;5;129;01mor\u001b[39;00m cv_orig\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m     candidate_params = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m     n_candidates = \u001b[38;5;28mlen\u001b[39m(candidate_params)\n\u001b[32m    962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\envs\\cs3244\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:324\u001b[39m, in \u001b[36mParameterSampler.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    317\u001b[39m         warnings.warn(\n\u001b[32m    318\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe total space of parameters \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is smaller \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthan n_iter=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. Running \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m iterations. For exhaustive \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msearches, use GridSearchCV.\u001b[39m\u001b[33m\"\u001b[39m % (grid_size, \u001b[38;5;28mself\u001b[39m.n_iter, grid_size),\n\u001b[32m    321\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    322\u001b[39m         )\n\u001b[32m    323\u001b[39m         n_iter = grid_size\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43msample_without_replacement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m param_grid[i]\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_random.pyx:342\u001b[39m, in \u001b[36msklearn.utils._random.sample_without_replacement\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_random.pyx:252\u001b[39m, in \u001b[36msklearn.utils._random._sample_without_replacement\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_random.pyx:100\u001b[39m, in \u001b[36msklearn.utils._random._sample_without_replacement_with_tracking_selection\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:796\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.randint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\_bounded_integers.pyx:1423\u001b[39m, in \u001b[36mnumpy.random._bounded_integers._rand_int32\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: high is out of bounds for int32"
     ]
    }
   ],
   "source": [
    "base_clf = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',\n",
    "    verbosity=0,\n",
    "    random_state=42,\n",
    "    device='cuda',\n",
    "    early_stopping_rounds=50,\n",
    "    n_jobs=-1\n",
    ")\n",
    "param_dist = {\n",
    "    #  20 choices from 50 → 2 000\n",
    "    'n_estimators':       list(np.linspace(50, 2000, 10, dtype=int)),\n",
    "\n",
    "    # 20 log‑spaced values from 1e‑3 → 1.0\n",
    "    'learning_rate':      list(np.logspace(-3, 0, 5)),\n",
    "\n",
    "    # all integers from 1 → 15\n",
    "    'max_depth':          list(range(1, 16)),\n",
    "\n",
    "    # all integers from 1 → 30\n",
    "    'min_child_weight':   list(range(1, 31)),\n",
    "\n",
    "    # 11 choices from 0 → 10\n",
    "    'gamma':              list(np.linspace(0, 10, 11)),\n",
    "\n",
    "    # 8 choices from 0.3 → 1.0\n",
    "    'subsample':          list(np.linspace(0.3, 1.0, 8)),\n",
    "    'colsample_bytree':   list(np.linspace(0.3, 1.0, 8)),\n",
    "    'colsample_bylevel':  list(np.linspace(0.3, 1.0, 8)),\n",
    "    'colsample_bynode':   list(np.linspace(0.3, 1.0, 8)),\n",
    "\n",
    "    # 10 log‑spaced values from 1e‑3 → 1e2\n",
    "    'reg_alpha':          list(np.logspace(-3, 2, 10)),\n",
    "    'reg_lambda':         list(np.logspace(-3, 2, 10)),\n",
    "\n",
    "    # all integers from 0 → 10\n",
    "    'max_delta_step':     list(range(0, 11)),\n",
    "\n",
    "    # 10 choices from 1 → 10\n",
    "    'scale_pos_weight':   list(np.linspace(1, 10, 10)),\n",
    "\n",
    "    # integers from 64 → 512 stepping by 32 (15 choices)\n",
    "    'max_bin':            list(range(64, 513, 32))\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_distributions=param_dist,\n",
    "    scoring='accuracy',\n",
    "    # n_iter=100, \n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "rand_search.fit(X_train_scaled, \n",
    "    y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    ")\n",
    "\n",
    "print(\"RandomSearch best params:\", rand_search.best_params_)\n",
    "print(\"RandomSearch best CV acc: {:.4f}\".format(rand_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rand_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# GridSearchCV fine‑tuning around Randomized best\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best = \u001b[43mrand_search\u001b[49m.best_params_\n\u001b[32m      3\u001b[39m grid_params = {\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m:         [\u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, best[\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m]-\u001b[32m2\u001b[39m), best[\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m], best[\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m]+\u001b[32m2\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmin_child_weight\u001b[39m\u001b[33m'\u001b[39m:  [\u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, best[\u001b[33m'\u001b[39m\u001b[33mmin_child_weight\u001b[39m\u001b[33m'\u001b[39m]-\u001b[32m2\u001b[39m), best[\u001b[33m'\u001b[39m\u001b[33mmin_child_weight\u001b[39m\u001b[33m'\u001b[39m], best[\u001b[33m'\u001b[39m\u001b[33mmin_child_weight\u001b[39m\u001b[33m'\u001b[39m]+\u001b[32m2\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_bin\u001b[39m\u001b[33m'\u001b[39m:           [\u001b[38;5;28mmax\u001b[39m(\u001b[32m32\u001b[39m, best[\u001b[33m'\u001b[39m\u001b[33mmax_bin\u001b[39m\u001b[33m'\u001b[39m]-\u001b[32m128\u001b[39m), best[\u001b[33m'\u001b[39m\u001b[33mmax_bin\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mmin\u001b[39m(\u001b[32m1024\u001b[39m, best[\u001b[33m'\u001b[39m\u001b[33mmax_bin\u001b[39m\u001b[33m'\u001b[39m]+\u001b[32m128\u001b[39m)]\n\u001b[32m     17\u001b[39m }\n\u001b[32m     19\u001b[39m grid_search = HalvingGridSearchCV(\n\u001b[32m     20\u001b[39m     estimator=XGBClassifier(\n\u001b[32m     21\u001b[39m         objective=\u001b[33m'\u001b[39m\u001b[33mbinary:logistic\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     n_jobs=\u001b[32m1\u001b[39m\n\u001b[32m     41\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'rand_search' is not defined"
     ]
    }
   ],
   "source": [
    "# GridSearchCV fine‑tuning around Randomized best\n",
    "best = rand_search.best_params_\n",
    "grid_params = {\n",
    "    'max_depth':         [max(1, best['max_depth']-2), best['max_depth'], best['max_depth']+2],\n",
    "    'min_child_weight':  [max(1, best['min_child_weight']-2), best['min_child_weight'], best['min_child_weight']+2],\n",
    "    'gamma':             [max(0.0, best['gamma']-1.0), best['gamma'], best['gamma']+1.0],\n",
    "    'subsample':         [max(0.1, best['subsample']-0.2), best['subsample'], min(1.0, best['subsample']+0.2)],\n",
    "    'colsample_bytree':  [max(0.1, best['colsample_bytree']-0.2), best['colsample_bytree'], min(1.0, best['colsample_bytree']+0.2)],\n",
    "    'colsample_bylevel': [max(0.1, best['colsample_bylevel']-0.2), best['colsample_bylevel'], min(1.0, best['colsample_bylevel']+0.2)],\n",
    "    'colsample_bynode':  [max(0.1, best['colsample_bynode']-0.2), best['colsample_bynode'], min(1.0, best['colsample_bynode']+0.2)],\n",
    "    'learning_rate':     [max(1e-4, best['learning_rate']/2), best['learning_rate'], min(1.0, best['learning_rate']*2)],\n",
    "    'reg_alpha':         [best['reg_alpha']/2, best['reg_alpha'], best['reg_alpha']*2],\n",
    "    'reg_lambda':        [best['reg_lambda']/2, best['reg_lambda'], best['reg_lambda']*2],\n",
    "    'scale_pos_weight':  [max(1, best['scale_pos_weight']-5), best['scale_pos_weight'], best['scale_pos_weight']+5],\n",
    "    'max_delta_step':    [max(0, best['max_delta_step']-2), best['max_delta_step'], best['max_delta_step']+2],\n",
    "    'max_bin':           [max(32, best['max_bin']-128), best['max_bin'], min(1024, best['max_bin']+128)]\n",
    "}\n",
    "\n",
    "grid_search = HalvingGridSearchCV(\n",
    "    estimator=XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        tree_method='hist',\n",
    "        random_state=42,\n",
    "        device='cuda',\n",
    "        gpu_id=0,\n",
    "        n_jobs=1,\n",
    "        # fix the other hyps from random search\n",
    "        n_estimators=best['n_estimators'],\n",
    "    ),\n",
    "    n_candidates=200,\n",
    "    param_grid=grid_params,\n",
    "    factor=3,\n",
    "    resource='n_estimators',\n",
    "    max_resources=best['n_estimators'],\n",
    "    min_resources=max(10, best['n_estimators']//5),\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"GridSearch best params:\", grid_search.best_params_)\n",
    "print(\"GridSearch best CV acc: {:.4f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Fit with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final fit with early stopping\n",
    "# Extend n_estimators so early stopping can trim it back\n",
    "final_params = {\n",
    "    **grid_search.best_params_,\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'reg_alpha':     best['reg_alpha'],\n",
    "    'reg_lambda':    best['reg_lambda'],\n",
    "    'tree_method':   'gpu_hist',\n",
    "    'predictor':     'gpu_predictor',\n",
    "    'gpu_id':        0\n",
    "}\n",
    "\n",
    "final_clf = XGBClassifier(\n",
    "    **final_params,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=30,\n",
    "    random_state=42\n",
    ")\n",
    "final_clf.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test\n",
    "y_test_pred = final_clf.predict(X_test_scaled)\n",
    "y_pred_binary = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "auc_roc = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Display results\n",
    "print(\"No Window\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(conf_matrix, \n",
    "                  index=['Actual Down', 'Actual Up'],\n",
    "                  columns=['Predicted Down', 'Predicted Up']))\n",
    "\n",
    "# Plot ROC curve\n",
    "RocCurveDisplay.from_predictions(y_test, y_test_pred)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs3244",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
